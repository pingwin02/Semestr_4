\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[polish]{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{multicol}

\lstdefinestyle{mystyle}{
    language=C,
    keywordstyle=\color{blue},
    identifierstyle=\color{teal},
    stringstyle=\color{red},
    commentstyle=\color{gray},
    showstringspaces=false,
    frame=single
}

\lstset{style=mystyle}

\usepackage[a4paper, margin=2.54cm]{geometry}


\title{Sprawozdanie - Projekt 2\\Układy równań liniowych\\
Implementacja metod Jacobiego, Gaussa-Seidla i LU}
\author{Damian Jankowski s188597}
\date{27 kwietnia 2023}

\begin{document}

\maketitle

\tableofcontents

\section{Wstęp}
Celem projektu było zaimplementowanie metod Jacobiego, 
Gaussa-Seidla i LU oraz porównanie wydajności,
dokładności, jak również czasu ich wykonania.

Każda z metod w różny sposób rozwiązuje pewien układ równań liniowych:

\begin{equation} 
    \boldsymbol{Ax = b}
\end{equation} 
gdzie: 
\begin{itemize}
    \item $\boldsymbol{A}$ -- macierz kwadratowa zawierająca współczynniki układu równań,
    \item $\boldsymbol{b}$ -- wektor wyrazów wolnych, 
    \item $\boldsymbol{x}$ -- wektor rozwiązań układu.
\end{itemize}

\pagebreak
Macierz $A$ została zdefiniowana jako macierz pasmowa o rozmiarze $997 \times 997$:

\begin{equation} \label{eq:macierzA}
A = \begin{bmatrix}
    a_1 & a_2 & a_3 & 0 & 0 & 0 & 0 & \dots & 0\\
    a_2 & a_1 & a_2 & a_3 & 0 & 0 & 0 & \dots & 0\\
    a_3 & a_2 & a_1 & a_2 & a_3 & 0 & 0 & \dots & 0\\
    0 & a_3 & a_2 & a_1 & a_2 & a_3 & 0 & \dots & 0\\
    0 & 0 & a_3 & a_2 & a_1 & a_2 & a_3 & \dots & 0\\
    0 & 0 & 0 & a_3 & a_2 & a_1 & a_2 & \dots & 0\\
    0 & 0 & 0 & 0 & a_3 & a_2 & a_1 & \dots & 0\\
    \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & \dots & 0 & 0 & 0 & a_3 & a_2 & a_1
\end{bmatrix}
\end{equation}
gdzie:
\begin{equation*}
a_1 = 10, \quad a_2 = -1, \quad a_3 = -1
\end{equation*}

Wektor $b$ długości $997$ został zdefiniowany jako:

\begin{equation}
b = \begin{bmatrix}
    sin(0 \cdot (f + 1))\\
    sin(1 \cdot (f + 1))\\
    sin(2 \cdot (f + 1))\\
    \vdots\\
    sin(996 \cdot (f + 1))
\end{bmatrix} \quad f = 8
\end{equation}

\section{Metody rozwiązywania układów równań liniowych}
Istnieje wiele metod rozwiązywania układów równań liniowych. 
W projekcie zostały zaimplementowane trzy z nich: metoda Jacobiego, Gaussa-Seidla i LU.

Pierwsze dwa należą do grupy metod iteracyjnych, 
natomiast ostatnia jest metodą bezpośrednią.

\subsection{Metody iteracyjne}
Metody iteracyjne polegają na wyznaczeniu 
kolejnych przybliżeń rozwiązania układu równań liniowych.

Korzystają one z tzw. macierzy: trójkątnej dolnej (\textit{Lower}) $L$, 
górnej (\textit{Upper}) $U$ oraz diagonalnej $D$,
które spełniają warunek:
\begin{equation}
    \boldsymbol{A = L + U + D}
\end{equation}

Warunkiem zakończenia iteracji jest osiągnięcie
zadanej dokładności lub maksymalnej liczby iteracji.
\subsubsection{Metoda Jacobiego}

Metoda Jacobiego polega na wyznaczeniu kolejnych przybliżeń
rozwiązania układu równań liniowych zgodnie ze wzorem:

\begin{equation}
    \boldsymbol{x^{(k+1)} = -D^{-1}(L + U)x^{(k)} + D^{-1}b}
\end{equation}
gdzie:
\begin{itemize}
    \item $\boldsymbol{x^{(k)}}$ - wektor przybliżenia rozwiązania w $k$-tej iteracji
\end{itemize}

\subsubsection{Metoda Gaussa-Seidla}

Metoda Gaussa-Seidla podobnie jak metoda Jacobiego polega 
na wyznaczeniu kolejnych przybliżeń, jednakże zgodnie z tym wzorem:

\begin{equation}
    \boldsymbol{x^{(k+1)} = -(D+L)^{-1}Ux^{(k)} + (D+L)^{-1}b}
\end{equation}

Problemem tej metody jest konieczność wyznaczenia macierzy $(D+L)^{-1}$,
czego powinno się unikać z racji dużej złożoności obliczeniowej.

Z tego powodu zamiast wyznaczać odwrotności macierzy $D+L$,
stosuje się tzw. podstawienie w przód (ang. \textit{forward substitution}).

\subsubsection{Podstawienie w przód}
Metoda podstawienia w przód polega na wyznaczeniu kolejnych
wartości wektora rozwiązań $\boldsymbol{x}$ układu równań $\boldsymbol{Lx = b}$,
w następujący sposób:

\begin{equation*}
    \boldsymbol{x_1 = \frac{b_1}{l_{11}}}
\end{equation*}

\begin{equation*}
    \boldsymbol{x_2 = \frac{b_2 - l_{21}x_1}{l_{22}}}
\end{equation*}

\begin{equation*}
    \boldsymbol{x_i = \frac{b_i - \sum_{j=1}^{i-1}l_{ij}x_j}{l_{ii}}}
\end{equation*}

\begin{equation*}
    \boldsymbol{\vdots}
\end{equation*}

\begin{equation*}
    \boldsymbol{x_n = \frac{b_n - \sum_{j=1}^{n-1}l_{nj}x_j}{l_{nn}}}
\end{equation*}

Koniecznym jest by macierz $\boldsymbol{L}$ była macierzą trójkątną dolną,
np. suma macierzy $D+L$ spełnia ten warunek.

\subsubsection{Podstawienie w tył}
Metoda podstawienia w tył podobnie jak metoda podstawienia w przód
polega na wyznaczeniu kolejnych wartości wektora rozwiązań $\boldsymbol{x}$ tym razem
układu równań $\boldsymbol{Ux = b}$. Jednakże w tym przypadku koniecznym jest
by macierz $\boldsymbol{U}$ była macierzą trójkątną górną.
Kolejne kroki wyglądają następująco:

\begin{equation*}
    \boldsymbol{x_n = \frac{b_n}{u_{nn}}}
\end{equation*}

\begin{equation*}
    \boldsymbol{x_{n-1} = \frac{b_{n-1} - u_{n-1,n}x_n}{u_{n-1,n-1}}}
\end{equation*}

\begin{equation*}
    \boldsymbol{x_i = \frac{b_i - \sum_{j=i+1}^{n}u_{ij}x_j}{u_{ii}}}
\end{equation*}

\begin{equation*}
    \boldsymbol{\vdots}
\end{equation*}

\begin{equation*}
    \boldsymbol{x_1 = \frac{b_1 - \sum_{j=2}^{n}u_{1j}x_j}{u_{11}}}
\end{equation*}

\subsubsection{Warunek zakończenia}
By sprawdzić czy osiągnięto zadaną dokładność należy przy każdej iteracji
sprawdzać czy norma tzw. wektora residuum (błędu rezydualnego) $\boldsymbol{res}$ jest mniejsza 
od zadanej wartości, np. $10^{-9}$.

Wektor residuum jest zdefiniowany następująco:
\begin{equation}
    \boldsymbol{res^{(k)} = Ax^{(k)}-b}
\end{equation}
W idealnej sytuacji powinien być równy wektorowi zerowemu.

Normę wektora residuum możemy obliczyć ze wzoru na normę euklidesową:

\begin{equation}
    \boldsymbol{||res^{(k)}|| = \sqrt{\sum_{i=1}^{n}(res_i^{(k)})^2}}
\end{equation}

Tym sposobem możemy z góry określić dokładność rozwiązania.

\pagebreak

Czasem może dojść do sytuacji, w której metoda nie zbiega do rozwiązania, np. norma
wektora residuum rośnie do nieskończoności. W takim przypadku należy sprawdzić czy
macierz $\boldsymbol{A}$ jest zdominowana przez przekątną, czyli czy zachodzi nierówność:

\begin{equation}\label{eq:domination}
    \boldsymbol{|a_{ii}| > \sum_{j=1, j\neq i}^{n}|a_{ij}| \quad dla \quad i=1,2,...,n}
\end{equation}

Dodatkowo można określić limit ilości iteracji, po których metoda powinna zakończyć
działanie, nawet jeśli nie osiągnęła zadanego poziomu dokładności. Do wykonania zadań
został wykorzystany limit 1000 iteracji.

\subsection{Metody bezpośrednie}
Metody bezpośrednie polegają na wyznaczeniu rozwiązania układu równań
bezpośrednio z macierzy współczynników $\boldsymbol{A}$. Odznaczają się one
dużą dokładnością, jednakże są czasochłonne i zasobożerne.

\subsubsection{Metoda faktoryzacji LU}

Metoda faktoryzacji LU polega na rozkładzie macierzy 
współczynników $\boldsymbol{A}$
na iloczyn macierzy $\boldsymbol{L}$ i $\boldsymbol{U}$:

\begin{equation}
    \boldsymbol{A = LU}
\end{equation}
gdzie:
\begin{itemize}
    \item $\boldsymbol{L}$ - macierz trójkątna dolna
    \item $\boldsymbol{U}$ - macierz trójkątna górna
\end{itemize}

Wtedy układ równań $\boldsymbol{Ax = b}$ można zapisać jako:

\begin{equation*}
    \boldsymbol{LUx = b}
\end{equation*}

By przejść dalej konieczne jest wyznaczenie potrzebnych macierzy pomocniczych.
\begin{enumerate}
    \item Na początku tworzy się macierz $\boldsymbol{L}$, która jest macierzą 
    jednostkową, czyli taką, której elementy na głównej przekątnej są równe 1.
    Natomiast macierz $\boldsymbol{U}$ to kopia macierzy $\boldsymbol{A}$.
    
    Faktoryzację LU opisać można tym kodem w języku C:
    
    \begin{lstlisting}
        for (int k = 0; k < n - 1; k++) {
            for (int j = k + 1; j < n; j++) {
                L[j][k] = U[j][k] / U[k][k];
                for (int i = k; i < n; i++) {
                    U[j][i] = U[j][i] - L[j][k] * U[k][i];
                }
            }
        }
    \end{lstlisting}

    \item Następnie metodą podstawiania w przód wyznacza 
    się wektor $\boldsymbol{y}$,
    który jest rozwiązaniem układu równań $\boldsymbol{Ly = b}$.

    \item Ostatnim krokiem jest wyznaczenie wektora rozwiązań $\boldsymbol{x}$,
    który jest rozwiązaniem układu równań $\boldsymbol{Ux = y}$.
    Z racji, że macierz $\boldsymbol{U}$ jest macierzą trójkątną górną,
    to wyznaczenie wektora $\boldsymbol{x}$ jest możliwe metodą 
    podstawienia w tył.
\end{enumerate}

Jak widać złożoność obliczeniowa tej metody wynosi $O(n^3)$, dlatego
nie jest zalecana do rozwiązywania układów równań o dużych rozmiarach.

\section{Implementacja metod i analiza wyników}
Implementację metod przedstawionych w poprzednim rozdziale wykonano w języku C.
Do pomiaru czasu wykorzystano funkcję \texttt{clock()} z biblioteki \texttt{time.h},
natomiast do wyznaczenia sinusa wykorzystano bibliotekę \texttt{math.h}.

W pliku \texttt{main.c} znajduje się funkcja \texttt{main()}, która odpowiada za
wykonywanie zadań. Plik \texttt{metody.c} zawiera implementacje metod iteracyjnych
oraz bezpośredniej LU, natomiast plik \texttt{funkcje.c} -- wszystkie implementacje
potrzebnych operacji na macierzach i wektorach.

\subsection{Zadanie A}
Zadanie A polegało na zaimplementowaniu układu równań przedstawionego we
wstępie.
\subsection{Zadanie B}
Zadanie B polegało na zaimplementowaniu metod iteracyjnych Jacobiego i 
Gaussa-Seidla oraz sprawdzeniu ilości iteracji potrzebnych do rozwiązania
układu równań z zadania A. Dodatkowo należało zmierzyć czas potrzebny na
rozwiązanie układu równań przez obie metody, tj. czas potrzebny by norma
wektora residuum była mniejsza od $10^{-9}$.
Wyniki zostały przedstawione poniżej.

\begin{table}[H]
    \begin{center}
        \begin{tabular}{| c | c | c |} 
        \hline
        Metoda & Czas & Ilość iteracji \\
        \hline
        Jacobi & 0.132s & 18 \\
        \hline
        Gauss-Seidel & 0.105s & 14 \\
        \hline
        \end{tabular}
        \caption{Wyniki pomiarów czasu i ilości iteracji dla zadania A}
    \end{center}
\end{table}

\begin{figure}[H]
    \includegraphics[width=0.75\textwidth]{zadB.png}
    \centering
    \caption{Wykres przedstawiający wartość normy wektora residuum}
    {od iteracji dla metod iteracyjnych}
\end{figure}

Jak widać na wykresie oraz w tabeli, metoda Gaussa-Seidla zbiega szybciej do
rozwiązania niż metoda Jacobiego. Jest to spowodowane tym, że w metodzie
Gaussa-Seidla wykorzystywane są już nowe wartości, które zostały wyznaczone
w tej samej iteracji, natomiast w metodzie Jacobiego wykorzystywane są
wartości z poprzedniej iteracji.

\subsection{Zadanie C}
Zadanie C podobnie jak B polegało na porównaniu działania metod iteracyjnych.
Natomiast trzeba było dokonać pewnej zmiany w budowie macierzy $\boldsymbol{A}$.
Wartość na głównej przekątnej macierzy $\boldsymbol{a_1}$ została zastąpiona
wartością 3. Dla takiego układu równań wyniki prezentują się następująco:

\begin{table}[H]
    \begin{center}
        \begin{tabular}{| c | c | c |} 
        \hline
        Metoda & Czas & Ilość iteracji \\
        \hline
        Jacobi & 7.324s & 1000 \\
        \hline
        Gauss-Seidel & 3.812s & 521 \\
        \hline
        \end{tabular}
        \caption{Wyniki pomiarów czasu i ilości iteracji dla zadania C}
    \end{center}
\end{table}

\begin{figure}[H]
    \includegraphics[width=0.75\textwidth]{zadC.png}
    \centering
    \caption{Wykres przedstawiający wartość normy wektora residuum}
    {od iteracji dla metod iteracyjnych}
\end{figure}

Obie metody nie zbiegły się do rozwiązania. Metoda Gaussa-Seidla zakończyła się
po 521 iteracjach z racji, że wartość normy wektora błędu rezydualnego doszła do nieskończoności.

Powodem takiego zachowania jest to, że macierz $\boldsymbol{A}$ nie jest
macierzą diagonalnie dominującą (\ref {eq:domination}).

\subsection{Zadanie D}
W zadaniu D trzeba było zaimplementować metodę faktoryzacji LU
i rozwiązać ten sam zmodyfikowany układ z zadania C, którego metody iteracyjne
nie zdołały rozwiązać. Rezultaty przedstawia poniższa tabela.

\begin{table}[H]
    \begin{center}
        \begin{tabular}{| c | c | c |} 
        \hline
        Metoda & Czas & Wartość normy błędu rezydualnego \\
        \hline
        \rule{0pt}{2.5ex}   
        Faktoryzacja LU & 1.14s & $2.414325 \cdot 10^{-13}$  \\
        \hline
        \end{tabular}
        \caption{Wyniki pomiaru czasu oraz normy błędu dla zadania D}
    \end{center}
\end{table}

Wartość normy błędu rezydualnego jest bardzo mała, co oznacza, że metoda
faktoryzacji LU poprawnie rozwiązała układ równań zadanego w zadaniu C.

\subsection{Zadanie E}
Zadanie E miało na celu porównanie czasu działania i ilości potrzebnych
iteracji do rozwiązania układu z zadania A dla różnych rozmiarów macierzy $A$.

Do wykonania zadania przyjęto następujące wartości $N$:

\begin{itemize}
    \begin{multicols}{3}
        \centering
        \item $N_1 = 100$
        \item $N_2 = 500$
        \item $N_3 = 1000$
        \item $N_4 = 2000$
        \item $N_5 = 3000$
        \item $N_6 = 5000$
        \item $N_7 = 8000$
        \item $N_8 = 10000$
        \item $N_9 = 12000$
    \end{multicols}
\end{itemize}

\begin{figure}[H]
    \includegraphics[width=0.65\textwidth]{zadE.png}
    \centering
    \caption{Wykres przedstawiający czas działania metod}
    {od rozmiaru macierzy $A$}
\end{figure}

\begin{figure}[H]
    \includegraphics[width=0.65\textwidth]{zadE_iter.png}
    \centering
    \caption{Wykres przedstawiający ilość iteracji metod iteracyjnych}
    {od rozmiaru macierzy $A$}
\end{figure}

Jak widać na wykresach, metoda faktoryzacji LU jest najwolniejsza (dla $N > 3000$
zdecydowałem o przerwaniu obliczeń dla tej metody, ponieważ czas wykonania był 
zbyt długi), natomiast metoda Gaussa-Seidla jest najszybsza. Potrzebowała ona również
mniejszej ilości iteracji niż metoda Jacobiego, aby osiągnąć odpowiednio dokładne rozwiązanie.

Co ciekawe ilość iteracji potrzebnych do rozwiązania układu równań dla obu metod 
nie rosła wraz z rozmiarem macierzy $A$. Wynika to z tego, że wartości w macierzy $A$
oraz w wektorze $b$ nie zmieniają się.

\section{Wnioski}

Wyniki testów pokazały, że metoda Gaussa-Siedla 
działa szybciej niż metoda Jacobiego w 
przypadku rozwiązywania danego układu równań.

Metoda faktoryzacji LU jest zdecydowanie wolniejsza od metod iteracyjnych,
natomiast radzi sobie z każdym układem równań, niezależnie od tego czy
macierz $\boldsymbol{A}$ jest diagonalnie dominująca czy nie.

Warto jednak zauważyć, że metody iteracyjne również mają swoje zalety, 
takie jak mniejsze wymagania pamięciowe, co może prowadzić do lepszych 
osiągów w niektórych przypadkach.

Ostatecznie, wybór metody rozwiązania liniowego układu równań zależy 
od specyficznych wymagań i ograniczeń problemu, takich jak dokładność, 
czas obliczeń, pamięć, struktura macierzy itp.

\renewcommand{\refname}{Źródła}
\begin{thebibliography}{100}
    \bibitem{intrukcja} 
    Kurs e-nauczanie Metody Numeryczne (Informatyka) - 2023\\
    \textit{Instrukcja do laboratorium 3}\\
    \textit{Wykład 3 i 4}
    \bibitem{iteracyjne}
    AGH,
    \textit{Metoda Jacobiego oraz Gaussa-Seidla}
    \\\url{http://sendzimir.metal.agh.edu.pl/~im4/metnum/dyd/pm/iteracyjne.htm}
    \bibitem{gauss}
    Wikipedia,
    \textit{Metoda Gaussa-Seidla}
    \\\url{https://pl.wikipedia.org/wiki/Metoda_Gaussa-Seidla}
    \bibitem{lu}
    Wikipedia,
    \textit{Faktoryzacja LU}
    \\\url{https://pl.wikipedia.org/wiki/Faktoryzacja_LU}
    \bibitem{lu2}
    Jerzy Wałaszek,
    \textit{Metody numeryczne - Rozkład LU i układ równań liniowych}
    \\\url{https://eduinf.waw.pl/inf/alg/008_nm/0026.php}
    \bibitem{dom}
    Wikipedia,
    \textit{Macierz diagonalnie dominująca}
    \\\url{https://pl.wikipedia.org/wiki/Macierz_diagonalnie_dominuj%C4%85ca}

\end{thebibliography}

\end{document}